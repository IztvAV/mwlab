import re

import torch.nn
import torchmetrics

from mwlab import BaseLModule, TouchstoneLDataModule, BaseLMWithMetrics, TouchstoneCodec
from filters import MWFilter, CouplingMatrix
import matplotlib.pyplot as plt
from torch.utils.data import Dataset
from filters.mwfilter_optim.base import FastMN2toSParamCalculation
from mwlab.lightning.base_lm_with_metrics import MAE_error
import torch.nn.functional as F


class MWFilterBaseLModule(BaseLModule):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)


    def predict_for(self, dm: TouchstoneLDataModule, idx: int) -> tuple[MWFilter, MWFilter]:
        # –í–æ–∑—å–º–µ–º –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ –ø–µ—Ä–≤—ã–π touchstone-—Ñ–∞–π–ª –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
        test_tds = dm.get_dataset(split="test", meta=True)
        # –ü–æ—Å–∫–æ–ª—å–∫—É swap_xy=True, —Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –º–µ–Ω—è–µ—Ç –º–µ—Å—Ç–∞–º–∏ –ø–∞—Ä—ã (y, x)
        y_t, x_t, meta = test_tds[idx]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö]

        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        orig_prms = dm.codec.decode_x(x_t)  # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        net = dm.codec.decode_s(y_t, meta)  # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç skrf.Network

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ S-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        pred_prms = self.predict_x(net)

        print(f"–ò—Å—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {orig_prms}")
        print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {pred_prms}")

        orig_fil = MWFilter.from_touchstone_dataset_item(({**meta['params'], **orig_prms}, net))
        pred_matrix = MWFilter.matrix_from_touchstone_data_parameters({**meta['params'], **pred_prms})
        s_pred = MWFilter.response_from_coupling_matrix(f0=orig_fil.f0, FBW=orig_fil.fbw, frange=orig_fil.f/1e6,
                                                        Q=orig_fil.Q, M=pred_matrix)
        pred_fil = MWFilter(order=int(meta['params']['N']), bw=meta['params']['bw'], f0=meta['params']['f0'], Q=meta['params']['Q'],
                 matrix=pred_matrix, frequency=orig_fil.f, s=s_pred, z0=orig_fil.z0)
        return orig_fil, pred_fil

    def plot_origin_vs_prediction(self, origin_fil: MWFilter, pred_fil: MWFilter):
        plt.figure()
        origin_fil.plot_s_db(m=0, n=0, label='S11 origin')
        origin_fil.plot_s_db(m=1, n=0, label='S21 origin')
        pred_fil.plot_s_db(m=0, n=0, label='S11 pred', ls=':')
        pred_fil.plot_s_db(m=1, n=0, label='S21 pred', ls=':')


class MWFilterBaseLMWithMetrics(BaseLMWithMetrics):
    def __init__(self, work_model, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.work_model = work_model

    def predict(self, dm: TouchstoneLDataModule, idx: int, with_scalers: bool=True):
        if idx == -1:  # –∑–Ω–∞—á–∏—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
            predictions = [self.predict_for(dm, i, with_scalers) for i in range(len(dm.get_dataset(split="test", meta=True)))]
        else:
            predictions = self.predict_for(dm, idx, with_scalers)
        return predictions

    def predict_for(self, dm: TouchstoneLDataModule, idx: int, with_scalers=True) -> tuple[MWFilter, MWFilter]:
        # –í–æ–∑—å–º–µ–º –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ –ø–µ—Ä–≤—ã–π touchstone-—Ñ–∞–π–ª –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
        test_tds = dm.get_dataset(split="test", meta=True)
        # –ü–æ—Å–∫–æ–ª—å–∫—É swap_xy=True, —Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –º–µ–Ω—è–µ—Ç –º–µ—Å—Ç–∞–º–∏ –ø–∞—Ä—ã (y, x)
        y_t, x_t, meta = test_tds[idx]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö]

        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        orig_prms = dm.codec.decode_x(x_t)  # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        net = dm.codec.decode_s(y_t, meta)  # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç skrf.Network

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ S-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        pred_prms = self.predict_x(net)
        if not with_scalers:
            pred_prms_vals = dm.scaler_out(torch.tensor(list(pred_prms.values())))
            orig_prms_vals = dm.scaler_out(torch.tensor(list(orig_prms.values())))
            pred_prms = dict(zip(pred_prms.keys(), list(torch.squeeze(pred_prms_vals, dim=0).numpy())))
            orig_prms = dict(zip(orig_prms.keys(), list(torch.squeeze(orig_prms_vals, dim=0).numpy())))

        print(f"–ò—Å—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {orig_prms}")
        print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {pred_prms}")

        orig_fil = MWFilter.from_touchstone_dataset_item(({**meta['params'], **orig_prms}, net))
        pred_fil = self.create_filter_from_prediction(orig_fil, pred_prms, meta)
        return orig_fil, pred_fil

    @staticmethod
    def create_filter_from_prediction(orig_fil: MWFilter, work_model_orig_fil: MWFilter, pred_prms: dict, codec: TouchstoneCodec) -> MWFilter:
        # Q = meta['params']['Q']
        Q = work_model_orig_fil.Q
        pred_matrix = MWFilter.matrix_from_touchstone_data_parameters(pred_prms, matrix_order=work_model_orig_fil.coupling_matrix.matrix_order)
        s_pred = MWFilter.response_from_coupling_matrix(f0=work_model_orig_fil.f0, FBW=work_model_orig_fil.fbw, frange=orig_fil.f / 1e6,
                                                        Q=Q, M=pred_matrix)
        pred_fil = MWFilter(order=work_model_orig_fil.coupling_matrix.matrix_order-2, bw=work_model_orig_fil.bw, f0=work_model_orig_fil.f0,
                            Q=Q,
                            matrix=pred_matrix, frequency=orig_fil.f, s=s_pred, z0=orig_fil.z0)
        return pred_fil

    def plot_origin_vs_prediction(self, origin_fil: MWFilter, pred_fil: MWFilter, title=None):
        plt.figure(figsize=(4, 3))
        origin_fil.plot_s_db(m=0, n=0, label='S11 origin')
        origin_fil.plot_s_db(m=1, n=0, label='S21 origin')
        origin_fil.plot_s_db(m=1, n=1, label='S22 origin')
        pred_fil.plot_s_db(m=0, n=0, label='S11 pred', ls=':')
        pred_fil.plot_s_db(m=1, n=0, label='S21 pred', ls=':')
        pred_fil.plot_s_db(m=1, n=1, label='S22 pred', ls=':')
        if title:
            plt.title(title)

    # # ---------------------------------------------------------------- forward
    # def forward(self, x: torch.Tensor) -> torch.Tensor:  # noqa: D401
    #     """X ‚Üí Z (—É—á–∏—Ç—ã–≤–∞–µ–º scaler_in, –µ—Å–ª–∏ –µ—Å—Ç—å)."""
    #     if self.scaler_in is not None:
    #         x = self.scaler_in(x)
    #     return self.model(x)

    @staticmethod
    def batched_sparams_from_M(M, w_norm, Q, fbw, a11, a22, b11, b22):
        """
        M:     [B, N, N] complex64 ‚Äî –º–∞—Ç—Ä–∏—Ü—ã —Å–≤—è–∑–∏ (—Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ Re)
        w_norm:[F] float32         ‚Äî –Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–µ—Ç–∫–∞ œâ (–∫–∞–∫ —É –≤–∞—à–µ–≥–æ —Ä–µ—à–∞—Ç–µ–ª—è)
        Q:     [B] float32
        fbw:   [B] float32
        a11,a22,b11,b22: [B] float32 ‚Äî —Ñ–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Œ∏1=a11+b11*w, Œ∏2=a22+b22*w (—Ä–∞–¥)
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
          S: [B, F, 2, 2] complex64  (S11,S21,S12=S21,S22) ‚Äî —É–∂–µ —Å —Ñ–∞–∑–æ–≤—ã–º–∏ –º–Ω–æ–∂–∏—Ç–µ–ª—è–º–∏.
        """

        device = M.device
        B, N, _ = M.shape
        F = int(w_norm.numel())

        # --- R –∏ I (–∫–∞–∫ –≤ –≤–∞—à–µ–º FastMN2toSParamCalculation)
        R = torch.zeros(N, N, dtype=torch.complex64, device=device)
        R[0, 0] = 1j
        R[-1, -1] = 1j

        I = torch.eye(N, N, dtype=torch.complex64, device=device)
        I[0, 0] = 0
        I[-1, -1] = 0

        # –º–∞—Å–∫–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–∏ –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Ä–µ–∑–æ–Ω–∞—Ç–æ—Ä–æ–≤ (–ø–æ–¥ G)
        Gmask = torch.eye(N, N, dtype=torch.complex64, device=device)
        Gmask[0, 0] = 0
        Gmask[-1, -1] = 0

        # --- –ú–∞—Ç—Ä–∏—Ü–∞ A(œâ) = (M-R) + œâ I - G(Q,fbw)
        MR = (M - R).unsqueeze(1)  # [B, 1, N, N]
        w_calc = w_norm.view(1, F, 1, 1).to(device)  # [1, F, 1, 1]

        coeff = (1.0 / (fbw * Q)).to(torch.float32).to(device)  # [B] real
        G_b = (1j * coeff).view(B, 1, 1, 1).to(torch.complex64) * Gmask.view(1, 1, N, N)  # [B,1,N,N]

        A = MR + w_calc * I.view(1, 1, N, N) - G_b  # [B, F, N, N]

        # --- RHS: e0 –∏ eN
        rhs = torch.zeros(B, F, N, 2, dtype=torch.complex64, device=device)
        rhs[:, :, 0, 0] = 1.0
        rhs[:, :, -1, 1] = 1.0

        # –†–µ—à–∞–µ–º A X = RHS –¥–ª—è –¥–≤—É—Ö –ø—Ä–∞–≤—ã—Ö —á–∞—Å—Ç–µ–π
        # torch.linalg.solve —Ä–∞–±–æ—Ç–∞–µ—Ç –±–∞—Ç—á–µ–≤–æ –ø–æ –ø–µ—Ä–≤—ã–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è–º
        X = torch.linalg.solve(A, rhs)  # [B, F, N, 2]

        x0 = X[..., 0]  # [B, F, N] ‚Äî A^{-1} @ e0
        xN = X[..., 1]  # [B, F, N] ‚Äî A^{-1} @ eN

        A00 = x0[..., 0]  # [B, F]
        AN0 = x0[..., -1]  # [B, F]
        ANN = xN[..., -1]  # [B, F]

        S11 = 1 + 2j * A00
        S21 = -2j * AN0
        S22 = 1 + 2j * ANN

        # --- –§–∞–∑–æ–≤—ã–µ –º–Ω–æ–∂–∏—Ç–µ–ª–∏ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
        # Œ∏1 = a11 + b11*w, Œ∏2 = a22 + b22*w
        w = w_norm.view(1, F).to(device)
        phi1 = a11.view(B, 1) + b11.view(B, 1) * w  # [B, F]
        phi2 = a22.view(B, 1) + b22.view(B, 1) * w  # [B, F]

        f11 = torch.exp(-1j * 2.0 * phi1).to(torch.complex64)  # [B, F]
        f22 = torch.exp(-1j * 2.0 * phi2).to(torch.complex64)  # [B, F]
        f21 = torch.exp(-1j * (phi1 + phi2)).to(torch.complex64)  # [B, F]

        S11 = S11 * f11
        S21 = S21 * f21
        S22 = S22 * f22

        # –°–æ–±–∏—Ä–∞–µ–º S –º–∞—Ç—Ä–∏—Ü—ã
        S = torch.zeros(B, F, 2, 2, dtype=torch.complex64, device=device)
        S[:, :, 0, 0] = S11
        S[:, :, 1, 1] = S22
        S[:, :, 0, 1] = S21
        S[:, :, 1, 0] = S21
        return S


    def unpack_batch_predictions(self, preds, names, N, device=None, dtype=torch.float32):
        """
           preds: [B, D] ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ —à–∫–∞–ª–µ –º–æ–¥–µ–ª–∏
           names: —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω (–¥–ª–∏–Ω–∞ D). –ò–º—è m_i_j -> —ç–ª–µ–º–µ–Ω—Ç –º–∞—Ç—Ä–∏—Ü—ã —Å–≤—è–∑–∏ (i,j).
           N: –ø–æ—Ä—è–¥–æ–∫ –ø–æ–ª–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã —Å–≤—è–∑–∏ (–≤–∫–ª—é—á–∞—è 2 –ø–æ—Ä—Ç–∞), –ø–æ –≤–∞—à–∏–º –∏–º–µ–Ω–∞–º —É –≤–∞—Å N=12.
           –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
             M:   [B, N, N] complex64 ‚Äî —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–∞—è (—Ä–µ–∞–ª—å–Ω–∞—è —á–∞—Å—Ç—å), –≥–æ—Ç–æ–≤–∞ –∫ —Ä–µ—à–∞—Ç–µ–ª—é
             Q:   [B]      float32
             fbw: [B]      float32   (–¥–æ–ª–µ–≤–∞—è –ø–æ–ª–æ—Å–∞, FBW)
             f0:  [B]      float32   (–ì—Ü, –µ—Å–ª–∏ —Ç–∞–∫ –æ–±—É—á–∞–ª–∏)
             a11,a22,b11,b22: [B] float32 ‚Äî —Ñ–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (—Ä–∞–¥)
           """
        if device is None: device = preds.device
        preds = self.scaler_out.inverse(preds).to(device=device, dtype=dtype)  # [B, D]
        B, D = preds.shape

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º M –∫–∞–∫ real –∏ –ø–æ—Ç–æ–º –ø—Ä–∏–≤–µ–¥—ë–º –∫ complex
        M_real = torch.zeros(B, N, N, dtype=dtype, device=device)

        # –ü–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –¥–ª—è —Å–∫–∞–ª—è—Ä–Ω—ã—Ö –≤—ã—Ö–æ–¥–æ–≤
        out_vals = {k: torch.zeros(B, dtype=dtype, device=device) for k in
                    ['Q', 'f0', 'bw', 'a11', 'a22', 'b11', 'b22']}

        # –ü—Ä–µ–¥–∫–æ–º–ø–∏–ª–∏—Ä—É–µ–º —Ä–µ–≥—ç–∫—Å–ø –¥–ª—è m_i_j
        pat = re.compile(r'^m_(\d+)_(\d+)$')

        for col, name in enumerate(names):
            m = pat.match(name)
            if m:
                i, j = int(m.group(1)), int(m.group(2))
                v = preds[:, col]  # [B]
                M_real[:, i, j] = v
                M_real[:, j, i] = v  # —Å–∏–º–º–µ—Ç—Ä–∏—è
            else:
                if name in out_vals:  # Q, bw, f0, a11, a22, b11, b22
                    out_vals[name] = preds[:, col]
                else:
                    # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ (–∏–ª–∏ –±—Ä–æ—Å–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ)
                    pass

        # –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Å–≤—è–∑–∏ (—Ä–µ–∞–ª—å–Ω—É—é —á–∞—Å—Ç—å –∫–ª–∞–¥—ë–º –≤ .real)
        M = M_real.to(torch.complex64)  # –∏–º. —á–∞—Å—Ç—å == 0, —Ç–∏–ø —Å–æ–≤–º–µ—Å—Ç–∏–º —Å —Ä–µ—à–∞—Ç–µ–ª–µ–º

        return (M,
                out_vals['Q'],
                out_vals['f0'],
                out_vals['bw'],
                out_vals['a11'], out_vals['a22'], out_vals['b11'], out_vals['b22'])


    def sparams_from_preds_batch(self, preds, names, N, w_norm, device=None):
        """
        preds -> (M,Q,fbw,f0,—Ñ–∞–∑—ã) -> S (–±–∞—Ç—á).
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
          S: [B, F, 2, 2] complex64
          aux: —Å–ª–æ–≤–∞—Ä—å —Å Q, fbw, f0 –∏ —Ç.–ø.
        """
        if device is None: device = preds.device
        (M, Q, f0, bw, a11, a22, b11, b22) = self.unpack_batch_predictions(
            preds, names, N, device=device, dtype=torch.float32
        )
        w_norm = torch.tensor(w_norm, dtype=torch.float32, device=device)

        fbw = bw/f0
        S = self.batched_sparams_from_M(M, w_norm, Q, fbw, a11, a22, b11, b22)

        aux = {'Q': Q, 'f0': f0, 'bw': bw, 'a11': a11, 'a22': a22, 'b11': b11, 'b22': b22}
        return S, aux

    @staticmethod
    def sbatch_to_features(S_batched: torch.Tensor,
                           order=None,
                           flatten: str = 'none'):
        """
        S_batched : [B, F, 2, 2] complex
        order     : —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω –∫–∞–Ω–∞–ª–æ–≤ (—Å–º. DEFAULT_ORDER). –ï—Å–ª–∏ None ‚Äî DEFAULT_ORDER.
        flatten   : 'none' -> [B, F, C]
                    'bf_c' -> [B*F, C]
                    'b_fc' -> [B, F*C]
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
          feats : float32 —Ç–µ–Ω–∑–æ—Ä —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π —Ñ–æ—Ä–º–æ–π
          idx_map : —Å–ª–æ–≤–∞—Ä—å {–∏–º—è_–∫–∞–Ω–∞–ª–∞: –∏–Ω–¥–µ–∫—Å_–∫–∞–Ω–∞–ª–∞} ‚Äî —É–¥–æ–±–Ω–æ –¥–ª—è –¥–µ–±–∞–≥–∞
        """
        B, F, _, _ = S_batched.shape

        feat_map = {
            'S1_1.real': S_batched[..., 0, 0].real,
            'S1_2.real': S_batched[..., 0, 1].real,
            'S2_1.real': S_batched[..., 1, 0].real,
            'S2_2.real': S_batched[..., 1, 1].real,
            'S1_1.imag': S_batched[..., 0, 0].imag,
            'S1_2.imag': S_batched[..., 0, 1].imag,
            'S2_1.imag': S_batched[..., 1, 0].imag,
            'S2_2.imag': S_batched[..., 1, 1].imag,
        }

        # –°—Ç–µ–∫ –ø–æ –æ—Å–∏ –∫–∞–Ω–∞–ª–æ–≤ -> [B, C, F]
        feats = torch.stack([feat_map[name].to(torch.float32) for name in order], dim=1)
        idx_map = {name: i for i, name in enumerate(order)}
        return feats, idx_map

    def features_to_sbatch(
            self,
            feats: torch.Tensor,
            order=None,
            *,
            layout: str = 'BCF',  # 'BCF' | 'BFC' | 'auto'  (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–∂–∏–¥–∞–µ–º [B,C,F])
            freq_len: int = None,  # –Ω—É–∂–Ω–æ –¥–ª—è 2D –≤—Ö–æ–¥–æ–≤
            dtype=torch.complex64
    ):
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ñ–∏—á–∏ –∫–∞–Ω–∞–ª–æ–≤ –≤ –±–∞—Ç—á S-–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

        feats  : —Ç–µ–Ω–∑–æ—Ä —Ñ–∏—á:
                 - [B, C, F] –ø—Ä–∏ layout='BCF' (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
                 - [B, F, C] –ø—Ä–∏ layout='BFC'
                 - [B*F, C]  –∏–ª–∏ [B, F*C] –ø—Ä–∏ layout='auto' (–Ω—É–∂–µ–Ω freq_len)
        order  : —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω –∫–∞–Ω–∞–ª–æ–≤ (—Å–º. DEFAULT_ORDER). –ï—Å–ª–∏ None ‚Äî DEFAULT_ORDER.
        layout : —Å—Ö–µ–º–∞ –≤—Ö–æ–¥–∞. –ü—Ä–∏ 'auto' –ø—ã—Ç–∞–µ–º—Å—è —É–≥–∞–¥–∞—Ç—å, –ø—Ä–∏ 2D –Ω–µ–æ–±—Ö–æ–¥–∏–º freq_len.
        freq_len: –¥–ª–∏–Ω–∞ —á–∞—Å—Ç–æ—Ç–Ω–æ–π –æ—Å–∏ F (–¥–ª—è 2D –≤—Ö–æ–¥–æ–≤).
        dtype  : —Ç–∏–ø –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –≤—ã—Ö–æ–¥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é complex64).

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
          S : [B, F, 2, 2] complex
          idx_map : {–∏–º—è_–∫–∞–Ω–∞–ª–∞: –∏–Ω–¥–µ–∫—Å_–∫–∞–Ω–∞–ª–∞}
        """
        C_expected = len(order)

        x = feats
        dev = x.device
        # ---- –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ [B, F, C] ----
        if x.ndim == 3:
            B, A, B_or_C = x.shape
            if layout.upper() == 'BCF' or (layout == 'auto' and A == C_expected):
                # [B, C, F] -> [B, F, C]
                x = x.transpose(1, 2).contiguous()
            elif layout.upper() == 'BFC' or (layout == 'auto' and B_or_C == C_expected):
                # [B, F, C] –∫–∞–∫ –µ—Å—Ç—å
                pass
            else:
                raise ValueError(f"–ù–µ –º–æ–≥—É –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞—Å–∫–ª–∞–¥–∫—É 3D –≤—Ö–æ–¥–∞ {tuple(feats.shape)} –ø—Ä–∏ layout='{layout}'.")
        elif x.ndim == 2:
            if freq_len is None:
                raise ValueError("–î–ª—è 2D –≤—Ö–æ–¥–∞ —É–∫–∞–∂–∏—Ç–µ freq_len.")
            N0, C_in = x.shape
            if C_in == C_expected:
                # [B*F, C] -> [B, F, C]
                if N0 % freq_len != 0:
                    raise ValueError(f"BF ({N0}) –Ω–µ –¥–µ–ª–∏—Ç—Å—è –Ω–∞ F ({freq_len}).")
                B = N0 // freq_len
                x = x.view(B, freq_len, C_expected)
            elif C_in % C_expected == 0 and N0 > 0 and N0 == N0:  # –≤–æ–∑–º–æ–∂–Ω–æ [B, F*C]
                # [B, F*C] -> [B, F, C]
                F = freq_len
                B = N0
                if C_in != F * C_expected:
                    raise ValueError(f"–û–∂–∏–¥–∞–ª–æ—Å—å F*C = {F * C_expected}, –∞ –ø—Ä–∏—à–ª–æ {C_in}.")
                x = x.view(B, F, C_expected)
            else:
                raise ValueError(
                    f"2D –≤—Ö–æ–¥ {tuple(feats.shape)} –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω. –û–∂–∏–¥–∞—é –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å = C ({C_expected}) "
                    f"–∏–ª–∏ –∫—Ä–∞—Ç–Ω—É—é F*C (freq_len –Ω—É–∂–µ–Ω).")
        else:
            raise ValueError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –≤—Ö–æ–¥—ã 2D –∏–ª–∏ 3D.")

        # x —Å–µ–π—á–∞—Å [B, F, C]
        B, F, C = x.shape
        if C != C_expected:
            raise ValueError(f"–ß–∏—Å–ª–æ –∫–∞–Ω–∞–ª–æ–≤ C={C} –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –¥–ª–∏–Ω–æ–π order={C_expected}.")

        # –°–ª–æ–≤–∞—Ä—å –∫–∞–Ω–∞–ª–æ–≤: –∏–º—è -> [B, F]
        chans = {name: x[..., i] for i, name in enumerate(order)}

        # –£—Ç–∏–ª–∏—Ç–∞: –ø–æ–ª—É—á–∏—Ç—å –∫–∞–Ω–∞–ª –∏–ª–∏ –Ω—É–ª–∏ (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –∫–∞–Ω–∞–ª–∞ –Ω–µ—Ç)
        def get(name):
            if name in chans:
                return chans[name]
            # –µ—Å–ª–∏ –∫–∞–∫–∏—Ö-—Ç–æ –∫–∞–Ω–∞–ª–æ–≤ –Ω–µ—Ç, –∑–∞–ø–æ–ª–Ω–∏–º –Ω—É–ª—è–º–∏
            return torch.zeros(B, F, device=dev, dtype=x.dtype)

        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ S
        S11 = get('S1_1.real').to(torch.float32) + 1j * get('S1_1.imag').to(torch.float32)
        S12 = get('S1_2.real').to(torch.float32) + 1j * get('S1_2.imag').to(torch.float32)
        S21 = get('S2_1.real').to(torch.float32) + 1j * get('S2_1.imag').to(torch.float32)
        S22 = get('S2_2.real').to(torch.float32) + 1j * get('S2_2.imag').to(torch.float32)

        S = torch.zeros(B, F, 2, 2, dtype=dtype, device=dev)
        S[..., 0, 0] = S11.to(dtype)
        S[..., 0, 1] = S12.to(dtype)
        S[..., 1, 0] = S21.to(dtype)
        S[..., 1, 1] = S22.to(dtype)

        idx_map = {name: i for i, name in enumerate(order)}
        return S, idx_map

    def calc_loss(self, x, y_t, preds):
        s_pred, aux = self.sparams_from_preds_batch(preds, self.work_model.codec.x_keys,
                                                    self.work_model.orig_filter.coupling_matrix.matrix_order,
                                                    self.work_model.orig_filter.f_norm)
        # s_pred_db = MWFilter.to_db(s_pred)

        s_pred_encoded, _ = self.sbatch_to_features(s_pred, order=self.work_model.codec.y_channels)
        s_in_decoded, _ = self.features_to_sbatch(x, order=self.work_model.codec.y_channels)

        # s_pred_norm = self.scaler_in(s_pred_encoded)

        loss = (self.loss_fn(preds, y_t) + 0.1*torch.nn.functional.l1_loss(s_pred_encoded, x)
                + 0.05 * torch.nn.functional.l1_loss(torch.angle(s_pred), torch.angle(s_in_decoded)))
        return loss

    def calc_mirror_loss(self, x: torch.Tensor, y_t: torch.Tensor) -> torch.Tensor:
        """
        –î–µ–ª–∞–µ—Ç "–∑–µ—Ä–∫–∞–ª—å–Ω—ã–π" –ø—Ä–æ—Ö–æ–¥ –∏ —Å—á–∏—Ç–∞–µ—Ç loss –¢–û–ß–ù–û —Ç–∞–∫ –∂–µ, –∫–∞–∫ calc_loss, –Ω–æ:
          1) –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ x –ø–µ—Ä–µ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è –º–µ—Å—Ç–∞–º–∏ –ø–æ –ø–æ—Ä—Ç–∞–º -> x_mir
          2) x_mir –ø–æ–¥–∞—ë—Ç—Å—è –≤ —Å–µ—Ç—å -> preds_mir
          3) preds_mir –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ –∏—Å—Ö–æ–¥–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –≤—ã—Ö–æ–¥–æ–≤ -> preds_mir_un
          4) loss —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø–æ —Ç–æ–π –∂–µ —Ñ–æ—Ä–º—É–ª–µ, –Ω–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏–¥—ë—Ç —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ (x, y_t),
             –∞ –Ω–µ —Å x_mir.

        –í–∞–∂–Ω–æ (–ø—Ä–æ inplace):
          - loss_fn –∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π –∫—É—Å–æ–∫ (—á–µ—Ä–µ–∑ sparams_from_preds_batch, –≥–¥–µ –º–æ–∂–µ—Ç –±—ã—Ç—å inverse/inplace)
            –∏—Å–ø–æ–ª—å–∑—É—é—Ç –†–ê–ó–ù–´–ï —Ç–µ–Ω–∑–æ—Ä—ã preds, —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å version mismatch –≤ autograd.
        """

        # ----------------------------------------------------------
        # 1) –ó–µ—Ä–∫–∞–ª–∏–º –≤—Ö–æ–¥ x –ø–æ –ø–æ—Ä—Ç–∞–º –ë–ï–ó inplace (—á–µ—Ä–µ–∑ permutation)
        # ----------------------------------------------------------
        y_order = self.work_model.codec.y_channels
        idx_y = {name: i for i, name in enumerate(y_order)}

        required = [
            'S1_1.real', 'S1_1.imag', 'S2_2.real', 'S2_2.imag',
            'S1_2.real', 'S1_2.imag', 'S2_1.real', 'S2_1.imag'
        ]
        if not all(k in idx_y for k in required):
            raise ValueError("–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –∑–µ—Ä–∫–∞–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ö–æ–¥–∞ x (S11/S22/S12/S21 real/imag).")

        C = x.shape[1]
        perm = torch.arange(C, device=x.device)

        # swap S11 <-> S22
        perm[idx_y['S1_1.real']], perm[idx_y['S2_2.real']] = perm[idx_y['S2_2.real']].clone(), perm[
            idx_y['S1_1.real']].clone()
        perm[idx_y['S1_1.imag']], perm[idx_y['S2_2.imag']] = perm[idx_y['S2_2.imag']].clone(), perm[
            idx_y['S1_1.imag']].clone()

        # swap S12 <-> S21
        perm[idx_y['S1_2.real']], perm[idx_y['S2_1.real']] = perm[idx_y['S2_1.real']].clone(), perm[
            idx_y['S1_2.real']].clone()
        perm[idx_y['S1_2.imag']], perm[idx_y['S2_1.imag']] = perm[idx_y['S2_1.imag']].clone(), perm[
            idx_y['S1_2.imag']].clone()

        x_mir = x.index_select(dim=1, index=perm)

        # ----------------------------------------------------------
        # 2) –ü—Ä–æ–≥–æ–Ω—è–µ–º —Å–µ—Ç—å –Ω–∞ –∑–µ—Ä–∫–∞–ª—å–Ω–æ–º –≤—Ö–æ–¥–µ
        # ----------------------------------------------------------
        preds_mir = self(x_mir)
        # [B, D]

        # ----------------------------------------------------------
        # 3) "–†–∞–∑–∑–µ—Ä–∫–∞–ª–∏–≤–∞–µ–º" preds_mir –æ–±—Ä–∞—Ç–Ω–æ –≤ –∏—Å—Ö–æ–¥–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ x_keys
        #    (–¥–µ–ª–∞–µ–º —ç—Ç–æ –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–æ–π –∫–æ–ª–æ–Ω–æ–∫)
        # ----------------------------------------------------------
        x_keys = self.work_model.codec.x_keys
        idx_x = {name: i for i, name in enumerate(x_keys)}

        K = self.work_model.orig_filter.coupling_matrix.matrix_order  # —Ä–∞–∑–º–µ—Ä –ø–æ–ª–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã (N+2)
        pat = re.compile(r'^m_(\d+)_(\d+)$')

        src_cols = []
        for name in x_keys:
            m = pat.match(name)
            if m:
                i, j = int(m.group(1)), int(m.group(2))
                ii, jj = (K - 1 - i), (K - 1 - j)
                src_name = f"m_{ii}_{jj}"
            elif name == 'a11':
                src_name = 'a22'
            elif name == 'a22':
                src_name = 'a11'
            elif name == 'b11':
                src_name = 'b22'
            elif name == 'b22':
                src_name = 'b11'
            else:
                src_name = name  # Q, f0, bw –∏ —Ç.–ø. —Å—á–∏—Ç–∞–µ–º –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω—ã–º–∏

            if src_name not in idx_x:
                # fallback: –µ—Å–ª–∏ –º–∞—Ç—Ä–∏—Ü–∞ —Ö—Ä–∞–Ω–∏—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∏–º —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–æ–º
                if m:
                    src_alt = f"m_{jj}_{ii}"
                    src_name = src_alt if src_alt in idx_x else name
                else:
                    src_name = name

            src_cols.append(idx_x[src_name])

        src_cols_t = torch.tensor(src_cols, device=preds_mir.device, dtype=torch.long)
        preds_mir_un = preds_mir.index_select(dim=1, index=src_cols_t)

        # ----------------------------------------------------------
        # 4) –°—á–∏—Ç–∞–µ–º loss —Ç–µ–º –∂–µ —Å–ø–æ—Å–æ–±–æ–º, —á—Ç–æ –≤ calc_loss, –Ω–æ vs –∏—Å—Ö–æ–¥–Ω—ã—Ö (x, y_t)
        # ----------------------------------------------------------
        # –í–∞–∂–Ω–æ: s_in_decoded –±–µ—Ä—ë–º –æ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ x, –∫–∞–∫ —Ç—ã –∏ —Ö–æ—Ç–µ–ª
        s_in_decoded, _ = self.features_to_sbatch(x, order=self.work_model.codec.y_channels)

        # –†–∞–∑–≤–æ–¥–∏–º —Ç–µ–Ω–∑–æ—Ä—ã, —á—Ç–æ–±—ã inverse()/–ø—Ä–æ—á–∏–µ inplace –Ω–µ –ª–æ–º–∞–ª–∏ backward loss_fn
        preds_for_loss = preds_mir_un.clone()
        preds_for_phys = preds_mir_un.clone()

        s_pred, _aux = self.sparams_from_preds_batch(
            preds_for_phys,
            self.work_model.codec.x_keys,
            self.work_model.orig_filter.coupling_matrix.matrix_order,
            self.work_model.orig_filter.f_norm
        )
        s_pred_encoded, _ = self.sbatch_to_features(s_pred, order=self.work_model.codec.y_channels)

        loss_mirror = (
                self.loss_fn(preds_for_loss, y_t)
                + 0.1 * F.l1_loss(s_pred_encoded, x)
                + 0.05 * F.l1_loss(torch.angle(s_pred), torch.angle(s_in_decoded))
        )

        return loss_mirror

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ shared step (train/val/test)
    def _shared_step(self, batch):
        x, y, _ = self._split_batch(batch)
        # preds = self(x[:,:-4,:])
        preds = self(x)
        # x_db = x[:,-4:,:]
        # —Ü–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤—Å–µ–≥–¥–∞ –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Ç–æ–π –∂–µ —à–∫–∞–ª–µ, —á—Ç–æ –∏ –º–æ–¥–µ–ª—å
        if self.scaler_out is not None:
            y = self.scaler_out(y)

        loss = self.calc_loss(x, y, preds)
        mirror_loss = self.calc_mirror_loss(x, y)
        # s_pred, aux = self.sparams_from_preds_batch(preds, self.work_model.codec.x_keys, self.work_model.orig_filter.coupling_matrix.matrix_order,
        #                                                self.work_model.orig_filter.f_norm)
        # # s_pred_db = MWFilter.to_db(s_pred)
        #
        # s_pred_encoded, _ = self.sbatch_to_features(s_pred, order=self.work_model.codec.y_channels)
        # s_in_decoded, _ = self.features_to_sbatch(x, order=self.work_model.codec.y_channels)
        #
        # # s_pred_norm = self.scaler_in(s_pred_encoded)
        #
        # loss = self.loss_fn(preds, y) + 0.1*torch.nn.functional.mse_loss(s_pred_encoded, x) + 0.1*torch.nn.functional.l1_loss(torch.angle(s_pred), torch.angle(s_in_decoded))
        return loss + mirror_loss

    # ======================================================================
    #                        validation / test loop
    # ======================================================================
    def validation_step(self, batch, batch_idx):
        x, y, _ = self._split_batch(batch)
        preds = self(x)
        y_t = self._prepare_targets(y)

        # s_pred, aux = self.sparams_from_preds_batch(preds, self.work_model.codec.x_keys,
        #                                             self.work_model.orig_filter.coupling_matrix.matrix_order,
        #                                             self.work_model.orig_filter.f_norm)
        # # s_pred_db = MWFilter.to_db(s_pred)
        #
        # s_pred_encoded, _ = self.sbatch_to_features(s_pred, order=self.work_model.codec.y_channels)
        # s_in_decoded, _ = self.features_to_sbatch(x, order=self.work_model.codec.y_channels)
        #
        # # s_pred_norm = self.scaler_in(s_pred_encoded)
        #
        # # loss = self.loss_fn(preds, y_t) + 0.1 * torch.nn.functional.mse_loss(s_pred_norm, x)
        # loss = self.loss_fn(preds, y_t) + 0.1 * torch.nn.functional.mse_loss(s_pred_encoded,
        #                                                                    x) + 0.1 * torch.nn.functional.l1_loss(
        #     torch.angle(s_pred), torch.angle(s_in_decoded))
        loss = self.calc_loss(x, y_t, preds) + self.calc_mirror_loss(x, y_t)

        self.log("val_loss", loss, on_epoch=True, prog_bar=True, batch_size=x.size(0))

        # üí° Flatten –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        preds_flat = preds.view(preds.size(0), -1)
        y_flat = y_t.view(y_t.size(0), -1)

        metric_dict = self.val_metrics(preds_flat, y_flat)
        self.log_dict(metric_dict, on_epoch=True, prog_bar=True, batch_size=x.size(0))
        acc = MAE_error(preds, y_t)
        self.log("val_acc", acc, prog_bar=True, on_epoch=True, batch_size=x.size(0))
        return loss



class MWFilterBaseLMWithMetricsCAE(MWFilterBaseLMWithMetrics):
    def __init__(self, origin_filter: MWFilter, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.origin_filter = origin_filter
        self.fast_calc = FastMN2toSParamCalculation(matrix_order=self.origin_filter.coupling_matrix.matrix_order,
                                                    wlist=self.origin_filter.f_norm, Q=self.origin_filter.Q,
                                                    fbw=self.origin_filter.fbw)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """X ‚Üí Z (—É—á–∏—Ç—ã–≤–∞–µ–º scaler_in, –µ—Å–ª–∏ –µ—Å—Ç—å)."""
        if self.scaler_in is not None:
            x = self.scaler_in(x)
        preds = self.model(x)
        matrix_factors = self.scaler_out.inverse(preds)
        s_origin_db = MWFilter.to_db(x)
        matrix = CouplingMatrix.from_factors(matrix_factors, self.origin_filter.coupling_matrix.links,
                                             self.origin_filter.coupling_matrix.matrix_order)
        s_pred = self.fast_calc.RespM2(matrix)
        s_pred_db = MWFilter.to_db(s_pred)
        loss = self.loss_fn(s_pred_db, s_origin_db)
        return loss

    def _shared_step(self, batch):
        x, y, _ = self._split_batch(batch)
        preds = self(x)
        return preds

