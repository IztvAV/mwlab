# mwlab/lightning/base_lm_with_metrics.py
"""
BaseLMWithMetrics
=================

Ð Ð°ÑÑˆÐ¸Ñ€ÑÐµÑ‚ `BaseLModule`, Ð´Ð¾Ð±Ð°Ð²Ð»ÑÑ Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð¸Ðµ Ð¸ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð»ÑŒÐ½Ñ‹Ñ…
Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð²Ð¾ Ð²Ñ€ÐµÐ¼Ñ **validate / test**.
"""

from __future__ import annotations

import torch
import torch.nn as nn
from torchmetrics import MetricCollection, MeanSquaredError, MeanAbsoluteError, R2Score
from typing import Optional, Callable, Any

from mwlab.lightning.base_lm import BaseLModule
from mwlab.codecs.touchstone_codec import TouchstoneCodec


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#                             BaseLMWithMetrics
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class BaseLMWithMetrics(BaseLModule):
    """
    Lightningâ€‘Ð¼Ð¾Ð´ÑƒÐ»ÑŒ Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¾Ð¹ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð¸ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð¼ÐµÑ‚Ñ€Ð¸Ðº.

    Ð’ÑÐµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ ÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ‚Ð¾Ñ€Ð° ÑÐ¾Ð²Ð¿Ð°Ð´Ð°ÑŽÑ‚ Ñ `BaseLModule`,
    Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‚ÑŒ `metrics` â€” Ð»Ð¸Ð±Ð¾ `MetricCollection`,
    Ð»Ð¸Ð±Ð¾ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ `{name: metric}`.

    ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹
    ----------
    model : nn.Module
        ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ.

    swap_xy : bool, default=False
        Ð•ÑÐ»Ð¸ True â€” Ñ€ÐµÑˆÐ°ÐµÑ‚ÑÑ Ð¸Ð½Ð²ÐµÑ€ÑÐ½Ð°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° (Y â†’ X).

    auto_decode : bool, default=True
        Ð•ÑÐ»Ð¸ True â€” Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ñ‹Ñ…Ð¾Ð´Ñ‹ Ð² TouchstoneData Ð½Ð° predict_step.

    codec : TouchstoneCodec, optional
        ÐšÐ¾Ð´ÐµÐº Ð´Ð»Ñ Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹.

    loss_fn : Callable, optional
        Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ð¾Ñ‚ÐµÑ€ÑŒ. ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ MSELoss().

    optimizer_cfg : dict, optional
        ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°.

    scheduler_cfg : dict, optional
        ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°.

    scaler_in : nn.Module, optional
        Ð¡ÐºÐµÐ¹Ð»ÐµÑ€ Ð´Ð»Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð²Ñ…Ð¾Ð´Ð°.

    scaler_out : nn.Module, optional
        Ð¡ÐºÐµÐ¹Ð»ÐµÑ€ Ð´Ð»Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð²Ñ‹Ñ…Ð¾Ð´Ð°.

    metrics : MetricCollection | dict, optional
        ÐÐ°Ð±Ð¾Ñ€ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð´Ð»Ñ Ñ€Ð°ÑÑ‡ÐµÑ‚Ð° Ð½Ð° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð¸ Ñ‚ÐµÑÑ‚Ðµ.
    metrics : MetricCollection | dict, optional
        ÐÐ°Ð±Ð¾Ñ€ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð´Ð»Ñ Ñ€Ð°ÑÑ‡ÐµÑ‚Ð° Ð½Ð° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð¸ Ñ‚ÐµÑÑ‚Ðµ.
        *Ð’Ð½ÑƒÑ‚Ñ€Ð¸* Ð¼Ð¾Ð´ÑƒÐ»Ñ Ð¾Ð½ ÐºÐ»Ð¾Ð½Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ð´Ð²Ð°Ð¶Ð´Ñ‹ (`val_*/ test_*`).
    """

    # ---------------------------------------------------------------- init
    def __init__(
        self,
        model: nn.Module,
        *,
        # ----- task mode ----------------------------------------------------
        swap_xy: bool = False,
        auto_decode: bool = True,
        codec: Optional[TouchstoneCodec] = None,
        # ----- optimisation -------------------------------------------------
        loss_fn: Optional[Callable] = None,
        optimizer_cfg: Optional[dict] = None,
        scheduler_cfg: Optional[dict] = None,
        # ----- scalers ------------------------------------------------------
        scaler_in: Optional[nn.Module] = None,
        scaler_out: Optional[nn.Module] = None,
        # ----- metrics ------------------------------------------------------
        metrics: Optional[MetricCollection | dict] = None,
    ):
        super().__init__(
            model=model,
            swap_xy=swap_xy,
            auto_decode=auto_decode,
            codec=codec,
            loss_fn=loss_fn,
            optimizer_cfg=optimizer_cfg,
            scheduler_cfg=scheduler_cfg,
            scaler_in=scaler_in,
            scaler_out=scaler_out,
        )

        # --- Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð½Ð°Ð±Ð¾Ñ€ Ð¼ÐµÑ‚Ñ€Ð¸Ðº ----------------------------------
        if metrics is None:
            metrics = {
                "mse": MeanSquaredError(),
                "mae": MeanAbsoluteError(),
                "r2" : R2Score()
            }
        if isinstance(metrics, dict):
            metrics = MetricCollection(metrics)

        self.val_metrics = metrics.clone(prefix="val_")
        self.test_metrics = metrics.clone(prefix="test_")

    # ======================================================================
    #                               helpers
    # ======================================================================
    def _prepare_targets(self, y: torch.Tensor) -> torch.Tensor:
        """
        ÐŸÑ€Ð¸Ð²Ð¾Ð´Ð¸Ñ‚ `y` Ðº Ñ‚Ð¾Ð¹ Ð¶Ðµ ÑˆÐºÐ°Ð»Ðµ, Ñ‡Ñ‚Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ loss Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸.
        """
        if self.scaler_out is not None:
            return self.scaler_out(y)
        return y

    # ======================================================================
    #                        validation / test loop
    # ======================================================================
    def validation_step(self, batch, batch_idx):
        x, y, _ = self._split_batch(batch)
        preds = self(x)
        y_t = self._prepare_targets(y)

        loss = self.loss_fn(preds, y_t)
        self.log("val_loss", loss, on_epoch=True, prog_bar=True, batch_size=x.size(0))

        # ðŸ’¡ Flatten Ð´Ð»Ñ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸
        #preds_flat = preds.view(preds.size(0), -1)
        #y_flat = y_t.view(y_t.size(0), -1)
        #metric_dict = self.val_metrics(preds_flat, y_flat)

        # ðŸ‘‰ Ð¿ÐµÑ€ÐµÐ´Ð°ÐµÐ¼ **Ð½Ðµ** ÑÐ¿Ð»ÑŽÑ‰ÐµÐ½Ð½Ñ‹Ðµ Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ñ‹
        metric_dict = self.val_metrics(preds, y_t)

        self.log_dict(metric_dict, on_epoch=True, prog_bar=True, batch_size=x.size(0))
        return loss

    def test_step(self, batch, batch_idx):
        x, y, _ = self._split_batch(batch)
        preds = self(x)
        y_t = self._prepare_targets(y)

        loss = self.loss_fn(preds, y_t)
        self.log("test_loss", loss, on_epoch=True, prog_bar=True, batch_size=x.size(0))

        # ðŸ’¡ Flatten Ð´Ð»Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
        #preds_flat = preds.view(preds.size(0), -1)
        #y_flat = y_t.view(y_t.size(0), -1)
        #metric_dict = self.test_metrics(preds_flat, y_flat)

        # ðŸ‘‰ Ð¿ÐµÑ€ÐµÐ´Ð°ÐµÐ¼ **Ð½Ðµ** ÑÐ¿Ð»ÑŽÑ‰ÐµÐ½Ð½Ñ‹Ðµ Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ñ‹
        metric_dict = self.val_metrics(preds, y_t)

        self.log_dict(metric_dict, on_epoch=True, prog_bar=True, batch_size=x.size(0))
        return loss

    # ---------------------------------------------------------------- repr
    def extra_repr(self) -> str:  # pragma: no cover
        metric_names = ",".join(sorted(self.val_metrics.keys()))
        return f"{super().extra_repr()}, metrics=[{metric_names}]"
