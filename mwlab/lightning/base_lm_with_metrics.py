# mwlab/mwfilter_lightning/base_lm_with_metrics.py
"""
BaseLMWithMetrics
=================

–†–∞—Å—à–∏—Ä—è–µ—Ç `BaseLModule`, –¥–æ–±–∞–≤–ª—è—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö
–º–µ—Ç—Ä–∏–∫ –≤–æ –≤—Ä–µ–º—è **validate / test**.
"""

from __future__ import annotations

import torch
import torch.nn as nn
from torchmetrics import MetricCollection, MeanSquaredError, MeanAbsoluteError, R2Score, Metric
from typing import Optional, Callable, Any

from mwlab.lightning.base_lm import BaseLModule
from mwlab.codecs.touchstone_codec import TouchstoneCodec


class RelativeAccuracy(Metric):
    """
    –ú–µ—Ç—Ä–∏–∫–∞ accuracy –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:
    Accuracy = 1 - mean(abs((pred - target) / target))
    –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç—Å—è 0 –ø—Ä–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–π –æ—à–∏–±–∫–µ > 1.
    """

    def __init__(self, eps: float = 1e-12, dist_sync_on_step=False):
        super().__init__(dist_sync_on_step=dist_sync_on_step)
        self.eps = eps
        self.add_state("sum_relative_error", default=torch.tensor(0.0), dist_reduce_fx="sum")
        self.add_state("total", default=torch.tensor(0), dist_reduce_fx="sum")

    def update(self, preds: torch.Tensor, target: torch.Tensor):
        if preds.shape != target.shape:
            raise ValueError(
                f"`preds` –∏ `target` –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—É—é —Ñ–æ—Ä–º—É, –Ω–æ –ø–æ–ª—É—á–∏–ª–∏ {preds.shape} –∏ {target.shape}")

        # –∏–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        rel_error = torch.abs((preds - target) / (target + self.eps))
        mean_error = rel_error.mean()

        self.sum_relative_error += mean_error
        self.total += 1

    def compute(self):
        avg_error = self.sum_relative_error / self.total
        return 1.0 - avg_error if avg_error < 1 else torch.tensor(0.0)



def MAE_error(output, target):
    error = torch.mean(torch.abs(output - target)).item()
    return 1 - error
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
#                             BaseLMWithMetrics
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
class BaseLMWithMetrics(BaseLModule):
    """
    Lightning‚Äë–º–æ–¥—É–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫.

    –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞ —Å–æ–≤–ø–∞–¥–∞—é—Ç —Å `BaseLModule`,
    –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å `metrics` ‚Äî –ª–∏–±–æ `MetricCollection`,
    –ª–∏–±–æ —Å–ª–æ–≤–∞—Ä—å `{name: metric}`.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    ----------
    model : nn.Module
        –ú–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.

    swap_xy : bool, default=False
        –ï—Å–ª–∏ True ‚Äî —Ä–µ—à–∞–µ—Ç—Å—è –∏–Ω–≤–µ—Ä—Å–Ω–∞—è –∑–∞–¥–∞—á–∞ (Y ‚Üí X).

    auto_decode : bool, default=True
        –ï—Å–ª–∏ True ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –≤—ã—Ö–æ–¥—ã –≤ TouchstoneData –Ω–∞ predict_step.

    codec : TouchstoneCodec, optional
        –ö–æ–¥–µ–∫ –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.

    loss_fn : Callable, optional
        –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é MSELoss().

    optimizer_cfg : dict, optional
        –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞.

    scheduler_cfg : dict, optional
        –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞.

    scaler_in : nn.Module, optional
        –°–∫–µ–π–ª–µ—Ä –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤—Ö–æ–¥–∞.

    scaler_out : nn.Module, optional
        –°–∫–µ–π–ª–µ—Ä –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤—ã—Ö–æ–¥–∞.

    metrics : MetricCollection | dict, optional
        –ù–∞–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–µ.
    metrics : MetricCollection | dict, optional
        –ù–∞–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–µ.
        *–í–Ω—É—Ç—Ä–∏* –º–æ–¥—É–ª—è –æ–Ω –∫–ª–æ–Ω–∏—Ä—É–µ—Ç—Å—è –¥–≤–∞–∂–¥—ã (`val_*/ test_*`).
    """

    # ---------------------------------------------------------------- init
    def __init__(
        self,
        model: nn.Module,
        *,
        # ----- task mode ----------------------------------------------------
        swap_xy: bool = False,
        auto_decode: bool = True,
        codec: Optional[TouchstoneCodec] = None,
        # ----- optimisation -------------------------------------------------
        loss_fn: Optional[Callable] = None,
        optimizer_cfg: Optional[dict] = None,
        scheduler_cfg: Optional[dict] = None,
        # ----- scalers ------------------------------------------------------
        scaler_in: Optional[nn.Module] = None,
        scaler_out: Optional[nn.Module] = None,
        # ----- metrics ------------------------------------------------------
        metrics: Optional[MetricCollection | dict] = None,
    ):
        super().__init__(
            model=model,
            swap_xy=swap_xy,
            auto_decode=auto_decode,
            codec=codec,
            loss_fn=loss_fn,
            optimizer_cfg=optimizer_cfg,
            scheduler_cfg=scheduler_cfg,
            scaler_in=scaler_in,
            scaler_out=scaler_out,
        )

        # --- –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞–±–æ—Ä –º–µ—Ç—Ä–∏–∫ ----------------------------------
        if metrics is None:
            metrics = {
                "mse": MeanSquaredError(),
                "mae": MeanAbsoluteError(),
                "r2" : R2Score(),
                "acc": RelativeAccuracy()
            }
        if isinstance(metrics, dict):
            metrics = MetricCollection(metrics)

        self.val_metrics = metrics.clone(prefix="val_")
        self.test_metrics = metrics.clone(prefix="test_")

    # ======================================================================
    #                               helpers
    # ======================================================================
    def _prepare_targets(self, y: torch.Tensor) -> torch.Tensor:
        """
        –ü—Ä–∏–≤–æ–¥–∏—Ç `y` –∫ —Ç–æ–π –∂–µ —à–∫–∞–ª–µ, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç loss –∏ –º–µ—Ç—Ä–∏–∫–∏.
        """
        if self.scaler_out is not None:
            return self.scaler_out(y)
        return y

    # ======================================================================
    #                        validation / test loop
    # ======================================================================
    def validation_step(self, batch, batch_idx):
        x, y, _ = self._split_batch(batch)
        preds = self(x)
        y_t = self._prepare_targets(y)

        loss = self.loss_fn(preds, y_t)
        self.log("val_loss", loss, on_epoch=True, prog_bar=True, batch_size=x.size(0))

        # üí° Flatten –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        preds_flat = preds.view(preds.size(0), -1)
        y_flat = y_t.view(y_t.size(0), -1)

        metric_dict = self.val_metrics(preds_flat, y_flat)
        self.log_dict(metric_dict, on_epoch=True, prog_bar=True, batch_size=x.size(0))
        acc = MAE_error(preds, y_t)
        self.log("val_acc", acc, prog_bar=True, on_epoch=True, batch_size=x.size(0))
        return loss

    def test_step(self, batch, batch_idx):
        x, y, _ = self._split_batch(batch)
        preds = self(x)
        y_t = self._prepare_targets(y)

        loss = self.loss_fn(preds, y_t)
        self.log("test_loss", loss, on_epoch=True, prog_bar=True, batch_size=x.size(0))

        # üí° Flatten –¥–ª—è –º–µ—Ç—Ä–∏–∫
        preds_flat = preds.view(preds.size(0), -1)
        y_flat = y_t.view(y_t.size(0), -1)

        metric_dict = self.test_metrics(preds_flat, y_flat)
        self.log_dict(metric_dict, on_epoch=True, prog_bar=True, batch_size=x.size(0))
        return loss

    # ---------------------------------------------------------------- repr
    def extra_repr(self) -> str:  # pragma: no cover
        metric_names = ",".join(sorted(self.val_metrics.keys()))
        return f"{super().extra_repr()}, metrics=[{metric_names}]"
